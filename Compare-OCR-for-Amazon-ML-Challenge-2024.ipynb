{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3919937,"sourceType":"datasetVersion","datasetId":2327240}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"To compare EasyOCR and Keras OCR on the dataset from Kaggle, you can follow the steps below. This code will load the dataset, apply both OCR models to extract text, and then compare their performance based on accuracy or other metrics like speed, F1 score, etc.\n\nSteps:\nInstall Dependencies: Make sure you have the required libraries installed.\nLoad Dataset: Load the images from the Kaggle dataset.\nRun OCR Models: Use EasyOCR and Keras OCR on the dataset.\nEvaluate Performance: Compare the output using metrics such as accuracy or timing.","metadata":{}},{"cell_type":"markdown","source":"# Import necessary libraries\n","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\n\nfrom glob import glob\nfrom tqdm.notebook import tqdm\n\nimport matplotlib.pyplot as plt\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:05:36.117266Z","iopub.execute_input":"2024-09-30T09:05:36.117709Z","iopub.status.idle":"2024-09-30T09:05:36.123499Z","shell.execute_reply.started":"2024-09-30T09:05:36.117655Z","shell.execute_reply":"2024-09-30T09:05:36.122236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load the annotation data from CSV and image data from parquet","metadata":{}},{"cell_type":"code","source":"annot = pd.read_csv('/kaggle/input/textocr-text-extraction-from-images-dataset/annot.csv')\nimgs = pd.read_parquet('/kaggle/input/textocr-text-extraction-from-images-dataset/img.parquet')\n\n# Load image paths\n# Use glob to find all image files in the specified directory\nimages = glob('/kaggle/input/textocr-text-extraction-from-images-dataset/train_val_images/train_images/*.jpg')  # Corrected to include *.jpg\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:05:36.126501Z","iopub.execute_input":"2024-09-30T09:05:36.126968Z","iopub.status.idle":"2024-09-30T09:05:40.160477Z","shell.execute_reply.started":"2024-09-30T09:05:36.126917Z","shell.execute_reply":"2024-09-30T09:05:40.159640Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Display first few rows of the annotations and images data","metadata":{}},{"cell_type":"code","source":"print(\"Annotations Data:\")\nprint(annot.head())\nprint(\"\\nImages Data:\")\nprint(imgs.head())","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:05:40.161681Z","iopub.execute_input":"2024-09-30T09:05:40.162132Z","iopub.status.idle":"2024-09-30T09:05:40.174007Z","shell.execute_reply.started":"2024-09-30T09:05:40.162084Z","shell.execute_reply":"2024-09-30T09:05:40.173005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the first image with their corresponding annotations\n\nimg_path = images[0]  # Get the image path\nimage = Image.open(img_path)  # Open the image\nplt.imshow(image)  # Display the image\nplt.axis('off')  # Hide axes\nplt.title(f\"Image: {img_path.split('/')[-1]}\")  # Title as the image name\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:05:40.175256Z","iopub.execute_input":"2024-09-30T09:05:40.175609Z","iopub.status.idle":"2024-09-30T09:05:40.510696Z","shell.execute_reply.started":"2024-09-30T09:05:40.175568Z","shell.execute_reply":"2024-09-30T09:05:40.509741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_id = images[0].split('/')[-1].split('.')[0] \nannot.query('image_id == @image_id')","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:05:40.512946Z","iopub.execute_input":"2024-09-30T09:05:40.513296Z","iopub.status.idle":"2024-09-30T09:05:40.570560Z","shell.execute_reply.started":"2024-09-30T09:05:40.513262Z","shell.execute_reply":"2024-09-30T09:05:40.569404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the first 9 images in a 3x3 grid\nfor i in range(9):  # Loop through the first 9 images\n    img_path = images[i]  # Get the image path\n    image = Image.open(img_path)  # Open the image\n    \n    plt.subplot(3, 3, i + 1)  # Create a subplot in a 3x3 grid\n    plt.imshow(image)  # Display the image\n    plt.axis('off')  # Hide axes\n    plt.title(f\"Image: {img_path.split('/')[-1]}\",fontsize=8)  # Title as the image name\n\nplt.tight_layout()  # Adjust layout to prevent overlap\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:05:40.571596Z","iopub.execute_input":"2024-09-30T09:05:40.571921Z","iopub.status.idle":"2024-09-30T09:05:42.175819Z","shell.execute_reply.started":"2024-09-30T09:05:40.571888Z","shell.execute_reply":"2024-09-30T09:05:42.174687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Initialize OCR models\n","metadata":{}},{"cell_type":"code","source":"# Initialize OCR models\n# please install both this if u dont have installed\n\n!pip install keras-ocr tensorflow==2.12.0\n!pip install numpy matplotlib\nimport keras_ocr\nimport easyocr\npipeline = keras_ocr.pipeline.Pipeline()  # Keras OCR\nreader = easyocr.Reader(['en'], gpu=True)  # EasyOCR","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:05:42.177411Z","iopub.execute_input":"2024-09-30T09:05:42.177802Z","iopub.status.idle":"2024-09-30T09:07:40.253515Z","shell.execute_reply.started":"2024-09-30T09:05:42.177755Z","shell.execute_reply":"2024-09-30T09:07:40.252466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Function to process OCR results\n","metadata":{}},{"cell_type":"code","source":"# Function to process EasyOCR results\ndef get_easyocr_results(image_paths):\n    dfs = []\n    for img in tqdm(image_paths):\n        result = reader.readtext(img)\n        img_id = img.split('/')[-1].split('.')[0]\n        img_df = pd.DataFrame(result, columns=['bbox', 'text', 'conf'])\n        img_df['img_id'] = img_id\n        dfs.append(img_df)\n    return pd.concat(dfs)\n\n# Function to process Keras OCR results\ndef get_kerasocr_results(image_paths):\n    dfs = []\n    for img in tqdm(image_paths):\n        results = pipeline.recognize([img])\n        img_id = img.split('/')[-1].split('.')[0]\n        img_df = pd.DataFrame(results[0], columns=['text', 'bbox'])\n        img_df['img_id'] = img_id\n        dfs.append(img_df)\n    return pd.concat(dfs)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:07:40.255064Z","iopub.execute_input":"2024-09-30T09:07:40.255595Z","iopub.status.idle":"2024-09-30T09:07:40.264106Z","shell.execute_reply.started":"2024-09-30T09:07:40.255538Z","shell.execute_reply":"2024-09-30T09:07:40.263220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get results for EasyOCR and Keras OCR\n\n","metadata":{}},{"cell_type":"code","source":"# Get results for EasyOCR and Keras OCR\neasyocr_df = get_easyocr_results(images[:25])  # Use first 25 images for EasyOCR\nkerasocr_df = get_kerasocr_results(images[:25])  # Use first 25 images for Keras OCR\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:07:40.265416Z","iopub.execute_input":"2024-09-30T09:07:40.265737Z","iopub.status.idle":"2024-09-30T09:15:52.380264Z","shell.execute_reply.started":"2024-09-30T09:07:40.265706Z","shell.execute_reply":"2024-09-30T09:15:52.379201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Function to plot comparison between EasyOCR and Keras OCR results\n","metadata":{}},{"cell_type":"code","source":"def plot_compare(img_fn, easyocr_df, kerasocr_df):\n    img_id = img_fn.split('/')[-1].split('.')[0]  # Extract the image ID\n    fig, axs = plt.subplots(1, 2, figsize=(15, 10))\n\n    # EasyOCR results for the current image\n    easy_results = easyocr_df.query('img_id == @img_id')[['text', 'bbox']].values.tolist()\n    easy_results = [(x[0], np.array(x[1])) for x in easy_results]  # Format as (text, bbox) pairs\n\n    # Visualize EasyOCR results\n    keras_ocr.tools.drawAnnotations(plt.imread(img_fn), easy_results, ax=axs[0])\n    axs[0].set_title('EasyOCR Results', fontsize=24)\n\n    # Keras OCR results for the current image\n    keras_results = kerasocr_df.query('img_id == @img_id')[['text', 'bbox']].values.tolist()\n    keras_results = [(x[0], np.array(x[1])) for x in keras_results]  # Format as (text, bbox) pairs\n\n    # Visualize Keras OCR results\n    keras_ocr.tools.drawAnnotations(plt.imread(img_fn), keras_results, ax=axs[1])\n    axs[1].set_title('Keras OCR Results', fontsize=24)\n\n    # Show the comparison plot\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:15:52.381772Z","iopub.execute_input":"2024-09-30T09:15:52.382074Z","iopub.status.idle":"2024-09-30T09:15:52.391007Z","shell.execute_reply.started":"2024-09-30T09:15:52.382042Z","shell.execute_reply":"2024-09-30T09:15:52.389914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Example usage: visualize OCR results for the first image\n","metadata":{}},{"cell_type":"code","source":"for img_path in images[:20]:  # Adjust the range as needed\n    plot_compare(img_path, easyocr_df, kerasocr_df)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T09:15:52.392155Z","iopub.execute_input":"2024-09-30T09:15:52.392496Z","iopub.status.idle":"2024-09-30T09:16:27.341493Z","shell.execute_reply.started":"2024-09-30T09:15:52.392464Z","shell.execute_reply":"2024-09-30T09:16:27.340553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}